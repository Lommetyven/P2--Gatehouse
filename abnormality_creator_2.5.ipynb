{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a578c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import sys, random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Union\n",
    "from scipy.ndimage import median_filter     # std-lib from SciPy ≥ 1.6\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Optional KeplerGL inline display\n",
    "# ---------------------------------------------------------------------------\n",
    "try:\n",
    "    from keplergl import KeplerGl  # type: ignore\n",
    "    from IPython.display import display  # type: ignore\n",
    "\n",
    "    _HAS_KEPLER = True\n",
    "except ImportError:\n",
    "    _HAS_KEPLER = False\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "NM_IN_DEG = 1.0 / 60.0  # ≈ 1 NM in degrees latitude at the equator\n",
    "\n",
    "\n",
    "def _delta_lat_lon(lat: float, bearing_deg: float, dist_nm: float) -> Tuple[float, float]:\n",
    "    \"\"\"Small‑displacement Δlat/Δlon (deg) for given bearing and distance (NM).\"\"\"\n",
    "    d = dist_nm * NM_IN_DEG\n",
    "    rad = np.deg2rad(bearing_deg)\n",
    "    return d * np.cos(rad), d * np.sin(rad) / np.cos(np.deg2rad(lat))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c2cf319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER CONFIG – edit and run the cell\n",
    "# ---------------------------------------------------------------------------\n",
    "SCRIPT_PATH = Path.cwd().parent\n",
    "\n",
    "EXISTING_ABNO = SCRIPT_PATH / \"data\" / \"new_abnormality_collection.csv\"\n",
    "INPUT_PATH = SCRIPT_PATH / \"data\" / \"Final_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec0f9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4335995, 8)\n",
      "Index(['# Timestamp', 'MMSI', 'Latitude', 'Longitude', 'ROT', 'SOG', 'COG',\n",
      "       'Heading'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 500000\n",
    "\n",
    "try:\n",
    "    base_chunks = pd.read_csv(INPUT_PATH, parse_dates=[\"# Timestamp\"], chunksize=chunk_size)\n",
    "    base = pd.concat(base_chunks)\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"INPUT_CSV is empty!\")\n",
    "    base = pd.DataFrame()\n",
    "\n",
    "print(base.shape)\n",
    "print(base.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cafda204",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MMSI = 636020765\n",
    "START_TIME = \"2025-02-07 02:23:42\"\n",
    "''''\n",
    "\n",
    "\n",
    "\n",
    "636093236 zigzag\n",
    "626281000 zigzag\n",
    "538009200 pickup\n",
    "257114000 deviation\n",
    "305286000 deviation \n",
    "636018261 zigzag\n",
    "257186000 pickup\n",
    "636020106 deviation\n",
    "219945000 zigzag\n",
    "538002778 deviation\n",
    "636092635 pickup\n",
    "636022249 zigzag\n",
    "266465000 deviation\n",
    "304717000 pickup\n",
    "257064430 zigzag\n",
    "230601000 deviation\n",
    "305773000 pickup\n",
    "538010240 zigzag\n",
    "255915583 deviation\n",
    "265859000 pickup (-700 ROT)\n",
    "265177000 zigzag\n",
    "314826000 deviation\n",
    "258003290 pickup\n",
    "257207000 zigzag\n",
    "538010456 deviation\n",
    "\n",
    "265410000 pickup\n",
    "563019500 zigzag\n",
    "275510000 deviation\n",
    "636022149 pickup\n",
    "636020765 zigzag\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "CONFIG = {\n",
    "    \"INPUT_CSV\": SCRIPT_PATH / \"output\" / \"single_ship.csv\", #Path til valgt\n",
    "    \"OUTPUT_CSV\": SCRIPT_PATH / \"output\" / \"anomaly_edit.csv\",\n",
    "    \"SEED\": 42, # Bare til random generation\n",
    "    \"ANOMALY\": \"zigzag\",   # deviation | speed_spike | stop | pickup | loop | zigzag | anchor_drift | gap | random (SKRIV HVILKE ANOMALY DU VIL HA)\n",
    "    \"PCT_SEGMENT\": 0.08,    # 0.08 er default. Hvor meget af tracket der skal bruges til en abnormalitet. \n",
    "    \"START_TS\": START_TIME,  # Random virker ikke så vælg et punkt\n",
    "    \"INTENSITY\": 2,       # 1.0 = default, >1 = stronger, <1 = milder\n",
    "    \"TARGET_MMSI\": TARGET_MMSI,  \n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa9f1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_existing = pd.read_csv(EXISTING_ABNO)\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"EXISTING_ABNORMALITIES is empty!. Creating new empty DataFrame.\")\n",
    "    df_existing = pd.DataFrame(columns=[ \"# Timestamp\",\"MMSI\",\"Latitude\",\"Longitude\",\"ROT\",\"SOG\",\"COG\",\"Heading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "865f4575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with CONFIG dict – edit at top as needed.\n",
      "\n",
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rasmu\\AppData\\Local\\Temp\\ipykernel_14980\\2113581059.py:199: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'zigzag' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[s:e, \"anomaly_type\"] = \"zigzag\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11dba65a9504e08a1b1009a90178c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'before':                 # Timestamp       MMSI   Latitude  Longitude  ROT   SOG  \\\n",
       "3566868 20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rasmu\\AppData\\Roaming\\Python\\Python312\\site-packages\\jupyter_client\\session.py:721: UserWarning: Message serialization failed with:\n",
      "Out of range float values are not JSON compliant: nan\n",
      "Supporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n",
      "  content = self.pack(content)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a4281021424103b985d3997f99a0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'after':              # Timestamp       MMSI   Latitude  Longitude  ROT   SOG    COG  \\\n",
       "0    20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] CSV written → output\\anomaly_edit.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "class AISAnomalyInjector:\n",
    "    \"\"\"Injects a single labelled anomaly segment into a ship track.\"\"\"\n",
    "\n",
    "    REQ = {\"# Timestamp\",\"MMSI\",\"Latitude\",\"Longitude\",\"ROT\",\"SOG\",\"COG\",\"Heading\"}\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, seed: Optional[int] = None):\n",
    "        missing = self.REQ - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"AIS dataframe missing required columns: {missing}\")\n",
    "        self.df = df.sort_values(\"# Timestamp\").reset_index(drop=True)\n",
    "        self.rng = random.Random(seed)\n",
    "        self.intensity: float = 1.0  # will be overwritten in `.inject()`\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def inject(\n",
    "        self,\n",
    "        kind: str = \"random\",\n",
    "        pct: float = 0.1,\n",
    "        start_ts: Optional[Union[str, pd.Timestamp]] = None,\n",
    "        intensity: float = 1.0,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Inject *one* anomaly of the given kind into the track.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kind : str\n",
    "            Anomaly type; \"random\" picks one at random.\n",
    "        pct : float\n",
    "            Fraction of the track to affect (window length).\n",
    "        start_ts : str | pd.Timestamp | None\n",
    "            Start timestamp for the anomaly window, or *None* → random start.\n",
    "        intensity : float, default 1.0\n",
    "            1.0 reproduces legacy behaviour; >1 exaggerates, <1 attenuates.\n",
    "        \"\"\"\n",
    "        if kind == \"random\":\n",
    "            kind = self.rng.choice([\n",
    "                \"deviation\", \"speed_spike\", \"stop\", \"pickup\", \"loop\", \"zigzag\", \"anchor_drift\", \"gap\",\n",
    "            ])\n",
    "        self.intensity = max(0, float(intensity))  # clip at 0\n",
    "\n",
    "        out = self.df.copy()\n",
    "        out[\"anomaly_type\"] = np.nan\n",
    "\n",
    "        s, e = self._pick_window(pct, start_ts)\n",
    "        a = out.loc[s, [\"Latitude\", \"Longitude\"]].to_numpy(float)\n",
    "        b = out.loc[e, [\"Latitude\", \"Longitude\"]].to_numpy(float)\n",
    "\n",
    "        getattr(self, f\"_do_{kind}\")(out, s, e, a, b)\n",
    "\n",
    "        # snap endpoints back exactly\n",
    "        out.loc[s, [\"Latitude\", \"Longitude\"]] = a\n",
    "        out.loc[e, [\"Latitude\", \"Longitude\"]] = b\n",
    "\n",
    "        self._recompute_kinematics(out, s, e) # Gør så koden ikke dividere med 0, fikser nogle store spikes og smoother den abnormale data ud\n",
    "        self._blend_sog(out, s, e)  # Denne får SOG til at matche den abnormale data med den originale data før og efter abnormaliteten.\n",
    "        self._insert_heading(out, s, e) # Fikser heading, så den også er realistisk\n",
    "        self._round_precision(out, s, e) # Runder numrene op så det matcher rigtig data.\n",
    "\n",
    "        return out\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Anomaly generators (modified to honour self.intensity)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    def _do_deviation(self, df, s, e, a, b):\n",
    "        n = e - s + 1\n",
    "        # 1) baseline\n",
    "        lat_base = np.linspace(a[0], b[0], n)\n",
    "        lon_base = np.linspace(a[1], b[1], n)\n",
    "        # 2) one perp offset\n",
    "        avg_lat = (a[0] + b[0]) / 2\n",
    "        bearing_ab = np.rad2deg(np.arctan2(\n",
    "            (b[1] - a[1]) * np.cos(np.deg2rad(avg_lat)),\n",
    "            (b[0] - a[0])\n",
    "        ))\n",
    "\n",
    "        perp_brg = (bearing_ab + 90) % 360\n",
    "        amp_nm = self.rng.uniform(1.0, 5.0) * self.intensity\n",
    "        dlat, dlon = _delta_lat_lon(a[0], perp_brg, amp_nm)\n",
    "        # 3) smooth ramp in/out\n",
    "        ramp = np.sin(np.linspace(0, np.pi, n))\n",
    "        # 4) write\n",
    "        df.loc[s:e, \"Latitude\"]  = lat_base + dlat * ramp\n",
    "        df.loc[s:e, \"Longitude\"] = lon_base + dlon * ramp\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"deviation\"\n",
    "\n",
    "    def _do_speed_spike(self, df, s, e, *_):\n",
    "        n = e - s + 1\n",
    "        base = self.rng.uniform(2, 4) * np.sin(np.linspace(0, np.pi, n)) ** 2 + 0.5\n",
    "        mult = 1 + (base - 1) * self.intensity  # scale away from 1\n",
    "        df.loc[s:e, \"SOG\"] *= mult\n",
    "        df.loc[s:e, \"ROT\"] += self.rng.uniform(-5, 5) * self.intensity * np.random.randn(n)\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"speed_spike\"\n",
    "\n",
    "    def _do_stop(self, df, s, e, a, b):\n",
    "        \"\"\"\n",
    "        Simulate a temporary stop: vessel smoothly slows to (almost) zero speed,\n",
    "        then accelerates back to normal.  Position follows the straight line\n",
    "        a→b so the track stays continuous; only the kinematics show the stop.\n",
    "\n",
    "        INTENSITY > 1 widens the low‑speed plateau, < 1 narrows it.\n",
    "        \"\"\"\n",
    "        n = e - s + 1\n",
    "\n",
    "        # --- keep positions on the baseline straight segment ---\n",
    "        df.loc[s:e, \"Latitude\"]  = np.linspace(a[0], b[0], n)\n",
    "        df.loc[s:e, \"Longitude\"] = np.linspace(a[1], b[1], n)\n",
    "\n",
    "        # --- speed profile: bell‑shaped slowdown to ~0 ---\n",
    "        ramp = np.sin(np.linspace(0, np.pi, n))            # 0→1→0\n",
    "        min_fac = 0.05                                     # 5 % of original SOG at full stop\n",
    "        # Scale ramp duration with intensity (>1 = wider stop, <1 = narrower)\n",
    "        width = np.clip(self.intensity, 0.1, 10)           # avoid div‑by‑0 / absurd spikes\n",
    "        fac = 1 - (1 - min_fac) * np.clip(ramp * width, 0, 1)\n",
    "        df.loc[s:e, \"SOG\"] *= fac\n",
    "\n",
    "        # --- little to no turning while stopped ---\n",
    "        df.loc[s:e, \"ROT\"] *= 0.1\n",
    "\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"stop\"\n",
    "\n",
    "    def _do_pickup(self, df, s, e, a, b):\n",
    "        n = e - s + 1\n",
    "        lat_base = np.linspace(a[0], b[0], n)\n",
    "        lon_base = np.linspace(a[1], b[1], n)\n",
    "\n",
    "        amp_nm = self.rng.uniform(1.0, 5.0) * self.intensity\n",
    "        side   = self.rng.choice([-1, 1])\n",
    "        avg_lat = (a[0] + b[0]) / 2\n",
    "        bearing_ab = np.rad2deg(np.arctan2(\n",
    "            (b[1] - a[1]) * np.cos(np.deg2rad(avg_lat)),\n",
    "            (b[0] - a[0])\n",
    "        ))\n",
    "        perp_brg = (bearing_ab + 90 * side) % 360\n",
    "        dlat, dlon = _delta_lat_lon(a[0], perp_brg, amp_nm)\n",
    "\n",
    "        # build a 3‑stage ramp: 0→1, hold, 1→0\n",
    "        ramp = np.zeros(n)\n",
    "        t1 = n // 3\n",
    "        t2 = 2 * n // 3\n",
    "        ramp[:t1]   = np.linspace(0, 1, t1)\n",
    "        ramp[t1:t2] = 1\n",
    "        ramp[t2:]   = np.linspace(1, 0, n - t2)\n",
    "        # soften\n",
    "        ramp = np.sin(ramp * np.pi / 2)\n",
    "\n",
    "        df.loc[s:e, \"Latitude\"]  = lat_base + dlat * ramp\n",
    "        df.loc[s:e, \"Longitude\"] = lon_base + dlon * ramp\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"pickup\"\n",
    "\n",
    "    def _do_loop(self, df, s, e, a, b):\n",
    "        n = e - s + 1\n",
    "        # baseline\n",
    "        lat_base = np.linspace(a[0], b[0], n)\n",
    "        lon_base = np.linspace(a[1], b[1], n)\n",
    "        # unit‑vector along a→b (in deg‑space)\n",
    "        avg_lat = (a[0] + b[0]) / 2\n",
    "        dx = b[0] - a[0]\n",
    "        dy = (b[1] - a[1]) * np.cos(np.deg2rad(avg_lat))\n",
    "        dist = np.hypot(dx, dy) or 1.0\n",
    "        ux, uy = dx / dist, dy / dist\n",
    "        # perp unit\n",
    "        px, py = -uy, ux\n",
    "        # loop radius\n",
    "        r_nm = self.rng.uniform(0.2, 0.5) * self.intensity\n",
    "        off = r_nm * NM_IN_DEG\n",
    "        # angle for 1→1.5 loops\n",
    "        θ = np.linspace(0, 2 * np.pi * self.rng.uniform(1, 1.5), n)\n",
    "        # compute offsets\n",
    "        lat_off = px * off * np.sin(θ)\n",
    "        lon_off = py * off * np.sin(θ) / np.cos(np.deg2rad(lat_base))\n",
    "        df.loc[s:e, \"Latitude\"]  = lat_base + lat_off\n",
    "        df.loc[s:e, \"Longitude\"] = lon_base + lon_off\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"loop\"\n",
    "\n",
    "    def _do_zigzag(self, df, s, e, a, b):\n",
    "        n = e - s + 1\n",
    "        # baseline\n",
    "        lat_base = np.linspace(a[0], b[0], n)\n",
    "        lon_base = np.linspace(a[1], b[1], n)\n",
    "        # pick # of half‑waves (even so endpoints zero)\n",
    "        waves = self.rng.randint(2, 8)\n",
    "        θ = np.linspace(0, waves * np.pi, n)\n",
    "        # lateral distance\n",
    "        offset_nm = self.rng.uniform(0.1, 0.3) * self.intensity\n",
    "        avg_lat = (a[0] + b[0]) / 2\n",
    "        # build perp vector (same as deviation)\n",
    "        bearing_ab = np.rad2deg(np.arctan2(\n",
    "            (b[1] - a[1]) * np.cos(np.deg2rad(avg_lat)),\n",
    "            (b[0] - a[0])\n",
    "        ))\n",
    "        perp_brg = (bearing_ab + 90) % 360\n",
    "        dlat, dlon = _delta_lat_lon(a[0], perp_brg, offset_nm)\n",
    "        # sinusoidal zigzag\n",
    "        sinz = np.sin(θ)\n",
    "        df.loc[s:e, \"Latitude\"]  = lat_base + dlat * sinz\n",
    "        df.loc[s:e, \"Longitude\"] = lon_base + dlon * sinz\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"zigzag\"\n",
    "\n",
    "    def _do_anchor_drift(self, df, s, e, a, b):\n",
    "        n = e - s + 1\n",
    "        # baseline\n",
    "        lat_base = np.linspace(a[0], b[0], n)\n",
    "        lon_base = np.linspace(a[1], b[1], n)\n",
    "        # small steady drift off one side\n",
    "        amp_nm = self.rng.uniform(0.05, 0.2) * self.intensity\n",
    "        avg_lat = (a[0] + b[0]) / 2\n",
    "        bearing_ab = np.rad2deg(np.arctan2(\n",
    "            (b[1] - a[1]) * np.cos(np.deg2rad(avg_lat)),\n",
    "            (b[0] - a[0])\n",
    "        ))\n",
    "        perp_brg = (bearing_ab + 90) % 360\n",
    "        dlat, dlon = _delta_lat_lon(a[0], perp_brg, amp_nm)\n",
    "        # smooth ramp in/out just like deviation\n",
    "        ramp = np.sin(np.linspace(0, np.pi, n))\n",
    "        df.loc[s:e, \"Latitude\"]  = lat_base + dlat * ramp\n",
    "        df.loc[s:e, \"Longitude\"] = lon_base + dlon * ramp\n",
    "        # keep it drifting slowly\n",
    "        df.loc[s:e, \"SOG\"] = self.rng.uniform(0.1, 0.5) * self.intensity\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"anchor_drift\"\n",
    "\n",
    "    def _do_gap(self, df, s, e, a, b):\n",
    "        n = e - s + 1\n",
    "        df.loc[s:e, \"Latitude\"]  = np.linspace(a[0], b[0], n)\n",
    "        df.loc[s:e, \"Longitude\"] = np.linspace(a[1], b[1], n)\n",
    "        df.loc[s:e, [\"ROT\", \"COG\", \"SOG\"]] = np.nan\n",
    "        df.loc[s:e, \"anomaly_type\"] = \"gap\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _recompute_kinematics(self, df, s, e):\n",
    "        \"\"\"\n",
    "        Overwrite COG, SOG, ROT for rows s…e so they reflect the\n",
    "        edited lat / lon.  Uses simple finite-differences in NM & sec.\n",
    "        \"\"\"\n",
    "        # 1. helpers ----------------------------------------------------\n",
    "        def _bearing(lat1, lon1, lat2, lon2):\n",
    "            x = np.deg2rad(lon2 - lon1) * np.cos(np.deg2rad((lat1 + lat2) / 2))\n",
    "            y = np.deg2rad(lat2 - lat1)\n",
    "            brg = (np.rad2deg(np.arctan2(x, y)) + 360) % 360\n",
    "            return brg\n",
    "\n",
    "        EARTH_NM = 60 * 180 / np.pi          # 1 rad ≈ 60 NM\n",
    "        def _dist_nm(lat1, lon1, lat2, lon2):\n",
    "            dφ = np.deg2rad(lat2 - lat1)\n",
    "            dλ = np.deg2rad(lon2 - lon1)\n",
    "            a = np.sin(dφ/2)**2 + np.cos(np.deg2rad(lat1))*np.cos(np.deg2rad(lat2))*np.sin(dλ/2)**2\n",
    "            return 2 * EARTH_NM * np.arcsin(np.sqrt(a))\n",
    "\n",
    "        # 2. slice we need ---------------------------------------------\n",
    "        lat  = df[\"Latitude\"].to_numpy()\n",
    "        lon  = df[\"Longitude\"].to_numpy()\n",
    "        ts   = df[\"# Timestamp\"].to_numpy(dtype='datetime64[ns]').astype('datetime64[s]').astype(int)\n",
    "\n",
    "        # idx + 1 because we need fwd diff; last row can reuse previous value\n",
    "        sl = slice(s, e)          # s … e-1\n",
    "        nxt = slice(s+1, e+1)     # s+1 … e\n",
    "\n",
    "        # --- choose exclusive slice s:e with .iloc so lengths match -------------\n",
    "        # COG --------------------------------------------------------------------\n",
    "        df.iloc[s:e, df.columns.get_loc(\"COG\")] = _bearing(\n",
    "            lat[s:e], lon[s:e],\n",
    "            lat[s+1:e+1], lon[s+1:e+1]\n",
    "        )\n",
    "\n",
    "        # SOG --------------------------------------------------------------------\n",
    "        dist_nm  = _dist_nm(lat[s:e], lon[s:e], lat[s+1:e+1], lon[s+1:e+1])\n",
    "        dt_hours = (ts[s+1:e+1] - ts[s:e]) / 3600          # sec → h\n",
    "        df.iloc[s:e, df.columns.get_loc(\"SOG\")] = dist_nm / dt_hours\n",
    "\n",
    "        # ROT --------------------------------------------------------------------\n",
    "        cog_rad = np.deg2rad(df[\"COG\"].to_numpy())\n",
    "        dcog    = np.unwrap(cog_rad)[s+1:e+1] - np.unwrap(cog_rad)[s:e]\n",
    "        df.iloc[s:e, df.columns.get_loc(\"ROT\")] = (\n",
    "            np.rad2deg(dcog) / ((ts[s+1:e+1] - ts[s:e]) / 60)   # deg / min\n",
    "        )\n",
    "\n",
    "    def _blend_sog(self, df, s, e, window=5):\n",
    "        \"\"\"\n",
    "        Linearly warps the *new* SOG values in rows s … e-1 so that they\n",
    "        join the original SOG that still exists in rows s-1 and e.\n",
    "        Also applies a short rolling-median to remove residual spikes.\n",
    "        \"\"\"\n",
    "        # indices for convenience\n",
    "        edited   = slice(s, e)          # rows with synthetic track\n",
    "        n        = e - s                # length of edited segment\n",
    "        if n <= 0:\n",
    "            return                      # nothing to do\n",
    "\n",
    "        # endpoint targets (the 'real' AIS values outside the splice)\n",
    "        sog_left  = df.at[s-1, \"SOG\"] if s > 0 else np.nan\n",
    "        sog_right = df.at[e,   \"SOG\"] if e < len(df) else np.nan\n",
    "\n",
    "        # synthetic SOG that came out of _recompute_kinematics\n",
    "        sog_new = df.loc[edited, \"SOG\"].to_numpy(dtype=float)\n",
    "\n",
    "        # If either neighbour is missing (NaN) just median-filter and quit\n",
    "        if np.isnan(sog_left) or np.isnan(sog_right):\n",
    "            df.loc[edited, \"SOG\"] = median_filter(sog_new, size=window,\n",
    "                                                mode=\"nearest\")\n",
    "            return\n",
    "\n",
    "        # -------- affine warp so that first and last points hit the targets ----\n",
    "        # y = a * x + b  ;  solve so that y0 = sog_left,  y_{n-1} = sog_right\n",
    "        a = (sog_right - sog_left) / (sog_new[-1] - sog_new[0] \\\n",
    "                                    + 1e-9)          # avoid /0\n",
    "        b = sog_left - a * sog_new[0]\n",
    "        sog_blended = a * sog_new + b\n",
    "\n",
    "        # optional light smoothing\n",
    "        sog_smoothed = median_filter(sog_blended, size=window, mode=\"nearest\")\n",
    "\n",
    "        # clip back into AIS range (0 … 102.2 kt) and write back\n",
    "        df.loc[edited, \"SOG\"] = np.clip(sog_smoothed, 0, 102.2)\n",
    "\n",
    "\n",
    "    def _insert_heading(self, df, s, e, window=7):\n",
    "        \"\"\"\n",
    "        Fill / overwrite the HDG column in rows s … e-1 so that it follows\n",
    "        the new path, then lightly smooth it.\n",
    "        \"\"\"\n",
    "        edited = slice(s, e)\n",
    "        if \"Heading\" not in df.columns:\n",
    "            df.insert(df.columns.get_loc(\"COG\") + 1, \"Heading\", np.nan)\n",
    "\n",
    "        # reuse the already unwrapped COG series (created in _recompute_kinematics)\n",
    "        hdg = df.loc[edited, \"COG\"].to_numpy(dtype=float)\n",
    "\n",
    "        # centre-aligned Savitzky–Golay filter (window must be odd)\n",
    "        from scipy.signal import savgol_filter\n",
    "        if window % 2 == 0:\n",
    "            window += 1                 # make it odd\n",
    "        hdg_smooth = savgol_filter(hdg, window_length=window, polyorder=2,\n",
    "                                mode=\"interp\")\n",
    "\n",
    "        # clip into valid range 0 … 359.9 and write back\n",
    "        df.loc[edited, \"Heading\"] = np.mod(hdg_smooth, 360)\n",
    "\n",
    "\n",
    "    def _round_precision(self, df, s, e):\n",
    "        \"\"\"\n",
    "        Round the freshly edited rows s … e-1 to AIS-style precision.\n",
    "\n",
    "            • ROT, SOG, COG  → 1 decimal  (e.g. 23.1)\n",
    "            • Latitude, Longitude → 6 decimals (e.g. 11.828833)\n",
    "            • Heading → integer 0-359\n",
    "        \"\"\"\n",
    "        edited = slice(s, e)\n",
    "\n",
    "        # 1-dp for the rates and courses\n",
    "        cols1dp = [\"ROT\", \"SOG\", \"COG\"]\n",
    "        df.loc[edited, cols1dp] = df.loc[edited, cols1dp].round(1)\n",
    "\n",
    "        # 6-dp for position\n",
    "        df.loc[edited, [\"Latitude\", \"Longitude\"]] = (\n",
    "            df.loc[edited, [\"Latitude\", \"Longitude\"]].round(6)\n",
    "        )\n",
    "\n",
    "        # integer heading (use rint to avoid -0.0)\n",
    "        df.loc[edited, \"Heading\"] = (\n",
    "            np.rint(df.loc[edited, \"Heading\"]).astype(\"Int64\")   # keeps NaN as <NA>\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def _pick_window(self, pct: float, start_ts: Optional[Union[str, pd.Timestamp]]):\n",
    "        \"\"\"Return start & end indices for the anomaly window.\"\"\"\n",
    "        L = len(self.df)\n",
    "        span = max(3, int(L * pct))\n",
    "        if start_ts is not None:\n",
    "            ts = pd.Timestamp(start_ts)\n",
    "            idx = self.df.index[self.df[\"# Timestamp\"] >= ts]\n",
    "            if idx.empty:\n",
    "                raise ValueError(\"START_TS is after the data ends\")\n",
    "            s = idx[0]\n",
    "            e = min(s + span, L - 1)\n",
    "            if e - s < 2:\n",
    "                raise ValueError(\"START_TS too close to track end for PCT_SEGMENT\")\n",
    "            return s, e\n",
    "\n",
    "        # --- random‑start mode ---\n",
    "        s = self.rng.randint(0, L - span - 1)\n",
    "        return s, s + span\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Kepler map helper\n",
    "# ---------------------------------------------------------------------------\n",
    "def show_maps(before: pd.DataFrame, after: pd.DataFrame):\n",
    "    \"\"\"Inline before/after layers if keplergl is available.\"\"\"\n",
    "    if not _HAS_KEPLER:\n",
    "        print(\"[!] keplergl not installed – skipping map display\")\n",
    "        return\n",
    "    display(KeplerGl(height=400, data={\"before\": before}))\n",
    "    display(KeplerGl(height=400, data={\"after\": after}))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Runner helper\n",
    "# ---------------------------------------------------------------------------\n",
    "def run(cfg: dict, df):\n",
    "    dst = Path(cfg[\"OUTPUT_CSV\"])\n",
    "    src = INPUT_PATH\n",
    "    base = df\n",
    "    \n",
    "    base = base[base[\"MMSI\"]==TARGET_MMSI]\n",
    "\n",
    "\n",
    "    injector = AISAnomalyInjector(base, seed=cfg[\"SEED\"])\n",
    "    augmented = injector.inject(cfg[\"ANOMALY\"],\n",
    "                                cfg[\"PCT_SEGMENT\"],\n",
    "                                cfg[\"START_TS\"],\n",
    "                                cfg[\"INTENSITY\"])\n",
    "\n",
    "    show_maps(base, augmented)\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    augmented = augmented.drop(\"anomaly_type\", axis=1)\n",
    "    # MY SHIT (AUGMENT INDICATOR AND RANDOM MMSI)\n",
    "    augmented[\"Label\"] = True\n",
    "\n",
    "    #new_mmsi = random.randint(100000000, 999999999)\n",
    "    #print(f\"New mmsi: {new_mmsi}\")\n",
    "    #augmented[\"MMSI\"] = new_mmsi\n",
    "    \n",
    "    # CHECK FOR EXCISTING MMSI IN AUG CSV FILE\n",
    "    if TARGET_MMSI not in df_existing['MMSI'].values:\n",
    "        df_updated = pd.concat([df_existing, augmented], ignore_index=True)\n",
    "        df_updated.to_csv(EXISTING_ABNO, index=False)\n",
    "        print(f\"[✓] CSV written → {dst.relative_to(SCRIPT_PATH)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Boat with that MMSI already exists. Skipped adding.\")\n",
    "\n",
    "\n",
    "    return augmented\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Entry‑point  –  Jupyter uses CONFIG, shell can use CLI\n",
    "# ---------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # If at least two positional args AND first arg isn’t an option, treat as CLI\n",
    "    if len(sys.argv) >= 3 and not sys.argv[1].startswith(\"-\"):\n",
    "        import argparse\n",
    "\n",
    "        p = argparse.ArgumentParser(description=\"Inject AIS anomaly and show maps\")\n",
    "        p.add_argument(\"input_csv\")\n",
    "        p.add_argument(\"output_csv\")\n",
    "        p.add_argument(\"--start\")\n",
    "        p.add_argument(\"--pct\",  type=float, default=CONFIG[\"PCT_SEGMENT\"])\n",
    "        p.add_argument(\"--kind\", default=\"random\")\n",
    "        p.add_argument(\"--seed\", type=int,    default=CONFIG[\"SEED\"])\n",
    "        # (INTENSITY flag deliberately left out to keep CLI unchanged unless requested)\n",
    "        args = p.parse_args()\n",
    "\n",
    "        cfg = CONFIG.copy()\n",
    "        cfg.update(INPUT_CSV=Path(args.input_csv),\n",
    "                   OUTPUT_CSV=Path(args.output_csv),\n",
    "                   START_TS=args.start,\n",
    "                   PCT_SEGMENT=args.pct,\n",
    "                   ANOMALY=args.kind,\n",
    "                   SEED=args.seed)\n",
    "        run(cfg, df = base)\n",
    "    else:\n",
    "        print(\"Running with CONFIG dict – edit at top as needed.\\n\")\n",
    "        run(CONFIG, df = base)\n",
    "\n",
    "# END OF CODE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
